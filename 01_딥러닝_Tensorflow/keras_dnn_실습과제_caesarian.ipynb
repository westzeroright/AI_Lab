{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed3c3962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56, 5), (56, 1))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logistic_regression_Caesarian.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "xy = np.loadtxt('caesarian.csv',delimiter=',',dtype=np.float32)\n",
    "\n",
    "# train data set\n",
    "x_data = xy[:56, :-1 ]\n",
    "y_data = xy[:56, [-1] ]\n",
    "\n",
    "x_train = np.array(x_data,dtype=np.float32)\n",
    "y_train = np.array(y_data,dtype=np.float32)\n",
    "x_train.shape,y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0a6e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 20)                120       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Callback\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs={}): \n",
    "        print('>>>myCallback:on_epoch_end',epoch)\n",
    "        if(logs.get('loss') < 0.53):\n",
    "            print('\\nReached 53% loss so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callbacks = myCallback() # 클래스의 인스턴스 생성\n",
    "\n",
    "\n",
    "# Dense Layer 구현 : 2층\n",
    "model = tf.keras.Sequential([\n",
    "    # 첫번째 층 출력 : [None,20],   활성화 함수 : 'relu', metrics:['accuracy']\n",
    "    tf.keras.layers.Dense(units=20,activation='relu',input_shape=(5,)) ,\n",
    "    # 두번째 층 출력 : [Non,2],   활성화 함수 : 'relu'\n",
    "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab2a410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "40/56 [====================>.........] - ETA: 0s - loss: 1.5019 - accuracy: 0.5000 >>>myCallback:on_epoch_end 0\n",
      "56/56 [==============================] - 1s 1ms/step - loss: 1.3199 - accuracy: 0.5179\n",
      "Epoch 2/700\n",
      "42/56 [=====================>........] - ETA: 0s - loss: 0.8556 - accuracy: 0.6190>>>myCallback:on_epoch_end 1\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7750 - accuracy: 0.6429\n",
      "Epoch 3/700\n",
      "45/56 [=======================>......] - ETA: 0s - loss: 0.6198 - accuracy: 0.6222>>>myCallback:on_epoch_end 2\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6041 - accuracy: 0.6607\n",
      "Epoch 4/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.7120 - accuracy: 0.6275>>>myCallback:on_epoch_end 3\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7546 - accuracy: 0.6250\n",
      "Epoch 5/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6206 - accuracy: 0.6731>>>myCallback:on_epoch_end 4\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.6786\n",
      "Epoch 6/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6170 - accuracy: 0.6226>>>myCallback:on_epoch_end 5\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6409 - accuracy: 0.6071\n",
      "Epoch 7/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.3652 - accuracy: 1.0000>>>myCallback:on_epoch_end 6\n",
      "56/56 [==============================] - 0s 904us/step - loss: 0.8034 - accuracy: 0.6607\n",
      "Epoch 8/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.6909>>>myCallback:on_epoch_end 7\n",
      "56/56 [==============================] - 0s 929us/step - loss: 0.6406 - accuracy: 0.6786\n",
      "Epoch 9/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.1002 - accuracy: 1.0000>>>myCallback:on_epoch_end 8\n",
      "56/56 [==============================] - 0s 867us/step - loss: 0.6483 - accuracy: 0.6250\n",
      "Epoch 10/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.4467 - accuracy: 1.0000>>>myCallback:on_epoch_end 9\n",
      "56/56 [==============================] - 0s 871us/step - loss: 0.7712 - accuracy: 0.6071\n",
      "Epoch 11/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.1175 - accuracy: 1.0000>>>myCallback:on_epoch_end 10\n",
      "56/56 [==============================] - 0s 862us/step - loss: 0.6533 - accuracy: 0.6429\n",
      "Epoch 12/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.2796 - accuracy: 1.0000>>>myCallback:on_epoch_end 11\n",
      "56/56 [==============================] - 0s 905us/step - loss: 0.6242 - accuracy: 0.7143\n",
      "Epoch 13/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.1018 - accuracy: 1.0000>>>myCallback:on_epoch_end 12\n",
      "56/56 [==============================] - 0s 884us/step - loss: 0.5844 - accuracy: 0.7679\n",
      "Epoch 14/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.1576 - accuracy: 1.0000>>>myCallback:on_epoch_end 13\n",
      "56/56 [==============================] - 0s 859us/step - loss: 0.8200 - accuracy: 0.6250\n",
      "Epoch 15/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 1.2049 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 14\n",
      "56/56 [==============================] - 0s 867us/step - loss: 0.6293 - accuracy: 0.6250\n",
      "Epoch 16/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 1.0793 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 15\n",
      "56/56 [==============================] - 0s 862us/step - loss: 0.6138 - accuracy: 0.7143\n",
      "Epoch 17/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.1961 - accuracy: 1.0000>>>myCallback:on_epoch_end 16\n",
      "56/56 [==============================] - 0s 841us/step - loss: 0.6101 - accuracy: 0.6964\n",
      "Epoch 18/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.1895 - accuracy: 1.0000>>>myCallback:on_epoch_end 17\n",
      "56/56 [==============================] - 0s 884us/step - loss: 0.5862 - accuracy: 0.6429\n",
      "Epoch 19/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.1778 - accuracy: 1.0000>>>myCallback:on_epoch_end 18\n",
      "56/56 [==============================] - 0s 858us/step - loss: 0.6033 - accuracy: 0.6964\n",
      "Epoch 20/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6277 - accuracy: 1.0000>>>myCallback:on_epoch_end 19\n",
      "56/56 [==============================] - 0s 843us/step - loss: 0.5901 - accuracy: 0.7143\n",
      "Epoch 21/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.0931 - accuracy: 1.0000>>>myCallback:on_epoch_end 20\n",
      "56/56 [==============================] - 0s 871us/step - loss: 0.5626 - accuracy: 0.7500\n",
      "Epoch 22/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.0590 - accuracy: 1.0000>>>myCallback:on_epoch_end 21\n",
      "56/56 [==============================] - 0s 841us/step - loss: 0.6249 - accuracy: 0.6429\n",
      "Epoch 23/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6203 - accuracy: 1.0000>>>myCallback:on_epoch_end 22\n",
      "56/56 [==============================] - 0s 890us/step - loss: 0.6517 - accuracy: 0.6429\n",
      "Epoch 24/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.2915 - accuracy: 1.0000>>>myCallback:on_epoch_end 23\n",
      "56/56 [==============================] - 0s 856us/step - loss: 0.6352 - accuracy: 0.6429\n",
      "Epoch 25/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7803 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 24\n",
      "56/56 [==============================] - 0s 856us/step - loss: 0.5656 - accuracy: 0.7321\n",
      "Epoch 26/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.3381 - accuracy: 1.0000>>>myCallback:on_epoch_end 25\n",
      "56/56 [==============================] - 0s 870us/step - loss: 0.5775 - accuracy: 0.7679\n",
      "Epoch 27/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7286 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 26\n",
      "56/56 [==============================] - 0s 876us/step - loss: 0.5694 - accuracy: 0.7500\n",
      "Epoch 28/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6031 - accuracy: 1.0000>>>myCallback:on_epoch_end 27\n",
      "56/56 [==============================] - 0s 866us/step - loss: 0.6018 - accuracy: 0.7321\n",
      "Epoch 29/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6698 - accuracy: 1.0000>>>myCallback:on_epoch_end 28\n",
      "56/56 [==============================] - 0s 822us/step - loss: 0.5585 - accuracy: 0.6786\n",
      "Epoch 30/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.3542 - accuracy: 1.0000>>>myCallback:on_epoch_end 29\n",
      "56/56 [==============================] - 0s 844us/step - loss: 0.6028 - accuracy: 0.7143\n",
      "Epoch 31/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.4575 - accuracy: 1.0000>>>myCallback:on_epoch_end 30\n",
      "\n",
      "Reached 53% loss so cancelling training!\n",
      "56/56 [==============================] - 0s 861us/step - loss: 0.5169 - accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "history = model.fit(x_train,y_train,epochs=700,batch_size=1,verbose=1,callbacks=[callbacks]) # verbose=1, 메세지를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d106a80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "epoch_count = range(1, len(history.history['loss']) + 1)\n",
    "plt.plot(epoch_count, history.history['loss'], 'r-')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f97cd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "preds = model.predict(x_train)\n",
    "np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596b8c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8323 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8323065638542175, 0.6666666865348816]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "x_data = xy[56:, :-1 ]\n",
    "y_data = xy[56:, [-1] ]\n",
    "\n",
    "x_test = np.array(x_data,dtype=np.float32)\n",
    "y_test = np.array(y_data,dtype=np.float32)\n",
    "\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712884c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 20)                120       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 42        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165\n",
      "Trainable params: 165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Callback\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs={}): \n",
    "        print('>>>myCallback:on_epoch_end',epoch)\n",
    "        if(logs.get('loss') < 0.53):\n",
    "            print('\\nReached 53% loss so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callbacks = myCallback() # 클래스의 인스턴스 생성\n",
    "\n",
    "\n",
    "# Dense Layer 구현 : 3층\n",
    "model = tf.keras.Sequential([\n",
    "    # 첫번째 층 출력 : [None,20],   활성화 함수 : 'relu', metrics:['accuracy']\n",
    "    tf.keras.layers.Dense(units=20,activation='relu',input_shape=(5,)) ,\n",
    "    # 두번째 층 출력 : [Non,2],   활성화 함수 : 'relu'\n",
    "    tf.keras.layers.Dense(units=2,activation='relu'),\n",
    "    # 세번째 층 출력 : [Non,2],   활성화 함수 : 'relu'\n",
    "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61e9aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.7155 - accuracy: 0.4510    >>>myCallback:on_epoch_end 0\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.4464\n",
      "Epoch 2/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5283    >>>myCallback:on_epoch_end 1\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 3/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5357>>>myCallback:on_epoch_end 2\n",
      "56/56 [==============================] - 0s 942us/step - loss: 0.6947 - accuracy: 0.5357\n",
      "Epoch 4/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6916 - accuracy: 0.5370    >>>myCallback:on_epoch_end 3\n",
      "56/56 [==============================] - 0s 953us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 5/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6934 - accuracy: 0.5283>>>myCallback:on_epoch_end 4\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 6/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6939 - accuracy: 0.5200>>>myCallback:on_epoch_end 5\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 7/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6900 - accuracy: 0.5577>>>myCallback:on_epoch_end 6\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 8/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6917 - accuracy: 0.5370>>>myCallback:on_epoch_end 7\n",
      "56/56 [==============================] - 0s 953us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 9/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6917 - accuracy: 0.5370>>>myCallback:on_epoch_end 8\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 10/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.5273    >>>myCallback:on_epoch_end 9\n",
      "56/56 [==============================] - 0s 945us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 11/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5357>>>myCallback:on_epoch_end 10\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 12/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.5283>>>myCallback:on_epoch_end 11\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 13/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5273>>>myCallback:on_epoch_end 12\n",
      "56/56 [==============================] - 0s 953us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 14/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6941 - accuracy: 0.5370>>>myCallback:on_epoch_end 13\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6941 - accuracy: 0.5357\n",
      "Epoch 15/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6920 - accuracy: 0.5370>>>myCallback:on_epoch_end 14\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 16/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6923 - accuracy: 0.5273>>>myCallback:on_epoch_end 15\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 17/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5273>>>myCallback:on_epoch_end 16\n",
      "56/56 [==============================] - 0s 958us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 18/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.5370>>>myCallback:on_epoch_end 17\n",
      "56/56 [==============================] - 0s 961us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 19/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5357    >>>myCallback:on_epoch_end 18\n",
      "56/56 [==============================] - 0s 916us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 20/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5370    >>>myCallback:on_epoch_end 19\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 21/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5357    >>>myCallback:on_epoch_end 20\n",
      "56/56 [==============================] - 0s 916us/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 22/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.5370>>>myCallback:on_epoch_end 21\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 23/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7636 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 22\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 24/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6943 - accuracy: 0.5283>>>myCallback:on_epoch_end 23\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 25/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6896 - accuracy: 0.5472>>>myCallback:on_epoch_end 24\n",
      "56/56 [==============================] - 0s 987us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 26/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5273    >>>myCallback:on_epoch_end 25\n",
      "56/56 [==============================] - 0s 954us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 27/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5357    >>>myCallback:on_epoch_end 26\n",
      "56/56 [==============================] - 0s 928us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 28/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6889 - accuracy: 0.5556>>>myCallback:on_epoch_end 27\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 29/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6866 - accuracy: 0.5769    >>>myCallback:on_epoch_end 28\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6943 - accuracy: 0.5357\n",
      "Epoch 30/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6907 - accuracy: 0.5472>>>myCallback:on_epoch_end 29\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 31/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6967 - accuracy: 0.5098    >>>myCallback:on_epoch_end 30\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5357\n",
      "Epoch 32/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5273    >>>myCallback:on_epoch_end 31\n",
      "56/56 [==============================] - 0s 943us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 33/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5357    >>>myCallback:on_epoch_end 32\n",
      "56/56 [==============================] - 0s 940us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 34/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6915 - accuracy: 0.5370    >>>myCallback:on_epoch_end 33\n",
      "56/56 [==============================] - 0s 977us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 35/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.5455    >>>myCallback:on_epoch_end 34\n",
      "56/56 [==============================] - 0s 943us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 36/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.5357    >>>myCallback:on_epoch_end 35\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 37/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.5357    >>>myCallback:on_epoch_end 36\n",
      "56/56 [==============================] - 0s 943us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 38/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5273    >>>myCallback:on_epoch_end 37\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 39/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5357    >>>myCallback:on_epoch_end 38\n",
      "56/56 [==============================] - 0s 927us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 40/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5357    >>>myCallback:on_epoch_end 39\n",
      "56/56 [==============================] - 0s 912us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 41/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5455>>>myCallback:on_epoch_end 40\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6943 - accuracy: 0.5357\n",
      "Epoch 42/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6903 - accuracy: 0.5472    >>>myCallback:on_epoch_end 41\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 43/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.5273>>>myCallback:on_epoch_end 42\n",
      "56/56 [==============================] - 0s 960us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 44/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.5455>>>myCallback:on_epoch_end 43\n",
      "56/56 [==============================] - 0s 952us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 45/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6941 - accuracy: 0.5283    >>>myCallback:on_epoch_end 44\n",
      "56/56 [==============================] - 0s 985us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 46/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6888 - accuracy: 0.5577    >>>myCallback:on_epoch_end 45\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 47/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6953 - accuracy: 0.5185>>>myCallback:on_epoch_end 46\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 48/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.5370>>>myCallback:on_epoch_end 47\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 49/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.5455>>>myCallback:on_epoch_end 48\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 50/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6925 - accuracy: 0.5283>>>myCallback:on_epoch_end 49\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 51/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5357    >>>myCallback:on_epoch_end 50\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 52/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5357    >>>myCallback:on_epoch_end 51\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 53/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5273>>>myCallback:on_epoch_end 52\n",
      "56/56 [==============================] - 0s 952us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 54/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5357>>>myCallback:on_epoch_end 53\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 55/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.5357>>>myCallback:on_epoch_end 54\n",
      "56/56 [==============================] - 0s 918us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 56/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5273    >>>myCallback:on_epoch_end 55\n",
      "56/56 [==============================] - 0s 936us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 57/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6954 - accuracy: 0.5000    >>>myCallback:on_epoch_end 56\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5357\n",
      "Epoch 58/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6892 - accuracy: 0.5577    >>>myCallback:on_epoch_end 57\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 59/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6916 - accuracy: 0.5370    >>>myCallback:on_epoch_end 58\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 60/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.5370>>>myCallback:on_epoch_end 59\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 61/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6948 - accuracy: 0.5273    >>>myCallback:on_epoch_end 60\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6939 - accuracy: 0.5357\n",
      "Epoch 62/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6944 - accuracy: 0.5273>>>myCallback:on_epoch_end 61\n",
      "56/56 [==============================] - 0s 958us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 63/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5357>>>myCallback:on_epoch_end 62\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 64/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7767 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 63\n",
      "56/56 [==============================] - 0s 908us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 65/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5357    >>>myCallback:on_epoch_end 64\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 66/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5273>>>myCallback:on_epoch_end 65\n",
      "56/56 [==============================] - 0s 952us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 67/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.5357>>>myCallback:on_epoch_end 66\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6950 - accuracy: 0.5357\n",
      "Epoch 68/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6919 - accuracy: 0.5370    >>>myCallback:on_epoch_end 67\n",
      "56/56 [==============================] - 0s 952us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 69/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5185>>>myCallback:on_epoch_end 68\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6910 - accuracy: 0.5357\n",
      "Epoch 70/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6977 - accuracy: 0.5357>>>myCallback:on_epoch_end 69\n",
      "56/56 [==============================] - 0s 926us/step - loss: 0.6977 - accuracy: 0.5357\n",
      "Epoch 71/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6905 - accuracy: 0.5385>>>myCallback:on_epoch_end 70\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6910 - accuracy: 0.5357\n",
      "Epoch 72/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6927 - accuracy: 0.5283>>>myCallback:on_epoch_end 71\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 73/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6902 - accuracy: 0.5472    >>>myCallback:on_epoch_end 72\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 74/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6953 - accuracy: 0.5094>>>myCallback:on_epoch_end 73\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 75/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5357>>>myCallback:on_epoch_end 74\n",
      "56/56 [==============================] - 0s 924us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 76/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6929 - accuracy: 0.5294>>>myCallback:on_epoch_end 75\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 77/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.5357    >>>myCallback:on_epoch_end 76\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 78/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.5370>>>myCallback:on_epoch_end 77\n",
      "56/56 [==============================] - 0s 966us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 79/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5455    >>>myCallback:on_epoch_end 78\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6941 - accuracy: 0.5357\n",
      "Epoch 80/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5660    >>>myCallback:on_epoch_end 79\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.5357\n",
      "Epoch 81/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6921 - accuracy: 0.5400>>>myCallback:on_epoch_end 80\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 82/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6932 - accuracy: 0.5400>>>myCallback:on_epoch_end 81\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 83/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.5370>>>myCallback:on_epoch_end 82\n",
      "56/56 [==============================] - 0s 967us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 84/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6950 - accuracy: 0.5185    >>>myCallback:on_epoch_end 83\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 85/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6234 - accuracy: 1.0000>>>myCallback:on_epoch_end 84\n",
      "56/56 [==============================] - 0s 903us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 86/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5357    >>>myCallback:on_epoch_end 85\n",
      "56/56 [==============================] - 0s 917us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 87/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5273>>>myCallback:on_epoch_end 86\n",
      "56/56 [==============================] - 0s 958us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 88/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.5357>>>myCallback:on_epoch_end 87\n",
      "56/56 [==============================] - 0s 935us/step - loss: 0.6988 - accuracy: 0.5357\n",
      "Epoch 89/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6906 - accuracy: 0.5370>>>myCallback:on_epoch_end 88\n",
      "56/56 [==============================] - 0s 967us/step - loss: 0.6908 - accuracy: 0.5357\n",
      "Epoch 90/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6911 - accuracy: 0.5455    >>>myCallback:on_epoch_end 89\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 91/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6934 - accuracy: 0.5283    >>>myCallback:on_epoch_end 90\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 92/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6979 - accuracy: 0.5000>>>myCallback:on_epoch_end 91\n",
      "56/56 [==============================] - 0s 991us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 93/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6896 - accuracy: 0.5490>>>myCallback:on_epoch_end 92\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 94/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6950 - accuracy: 0.5192    >>>myCallback:on_epoch_end 93\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 95/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6911 - accuracy: 0.5455>>>myCallback:on_epoch_end 94\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 96/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5273>>>myCallback:on_epoch_end 95\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 97/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5357>>>myCallback:on_epoch_end 96\n",
      "56/56 [==============================] - 0s 929us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 98/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5455>>>myCallback:on_epoch_end 97\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.6949 - accuracy: 0.5357\n",
      "Epoch 99/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.5273    >>>myCallback:on_epoch_end 98\n",
      "56/56 [==============================] - 0s 949us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 100/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5273>>>myCallback:on_epoch_end 99\n",
      "56/56 [==============================] - 0s 959us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 101/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.5370    >>>myCallback:on_epoch_end 100\n",
      "56/56 [==============================] - 0s 947us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 102/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7726 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 101\n",
      "56/56 [==============================] - 0s 911us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 103/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5357>>>myCallback:on_epoch_end 102\n",
      "56/56 [==============================] - 0s 942us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 104/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6918 - accuracy: 0.5370    >>>myCallback:on_epoch_end 103\n",
      "56/56 [==============================] - 0s 954us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 105/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6936 - accuracy: 0.5273>>>myCallback:on_epoch_end 104\n",
      "56/56 [==============================] - 0s 949us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 106/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5357    >>>myCallback:on_epoch_end 105\n",
      "56/56 [==============================] - 0s 932us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 107/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6277 - accuracy: 1.0000>>>myCallback:on_epoch_end 106\n",
      "56/56 [==============================] - 0s 907us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 108/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6904 - accuracy: 0.5455>>>myCallback:on_epoch_end 107\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 109/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.5455    >>>myCallback:on_epoch_end 108\n",
      "56/56 [==============================] - 0s 929us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 110/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.5455>>>myCallback:on_epoch_end 109\n",
      "56/56 [==============================] - 0s 956us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 111/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.5357    >>>myCallback:on_epoch_end 110\n",
      "56/56 [==============================] - 0s 915us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 112/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6900 - accuracy: 0.5556>>>myCallback:on_epoch_end 111\n",
      "56/56 [==============================] - 0s 949us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 113/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.5455>>>myCallback:on_epoch_end 112\n",
      "56/56 [==============================] - 0s 935us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 114/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6916 - accuracy: 0.5370>>>myCallback:on_epoch_end 113\n",
      "56/56 [==============================] - 0s 977us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 115/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5370>>>myCallback:on_epoch_end 114\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 116/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6945 - accuracy: 0.5185>>>myCallback:on_epoch_end 115\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 117/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6926 - accuracy: 0.5370>>>myCallback:on_epoch_end 116\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 118/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6981 - accuracy: 0.5000>>>myCallback:on_epoch_end 117\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5357\n",
      "Epoch 119/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6897 - accuracy: 0.5510>>>myCallback:on_epoch_end 118\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 120/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6926 - accuracy: 0.5400>>>myCallback:on_epoch_end 119\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 121/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6953 - accuracy: 0.5200    >>>myCallback:on_epoch_end 120\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 122/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.5094    >>>myCallback:on_epoch_end 121\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 123/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6916 - accuracy: 0.5370    >>>myCallback:on_epoch_end 122\n",
      "56/56 [==============================] - 0s 979us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 124/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6941 - accuracy: 0.5192>>>myCallback:on_epoch_end 123\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 125/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6941 - accuracy: 0.5185    >>>myCallback:on_epoch_end 124\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 126/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6901 - accuracy: 0.5490    >>>myCallback:on_epoch_end 125\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 127/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6897 - accuracy: 0.5472    >>>myCallback:on_epoch_end 126\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 128/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.5273>>>myCallback:on_epoch_end 127\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 129/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5370>>>myCallback:on_epoch_end 128\n",
      "56/56 [==============================] - 0s 990us/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 130/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6913 - accuracy: 0.5385>>>myCallback:on_epoch_end 129\n",
      "56/56 [==============================] - 0s 995us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 131/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6954 - accuracy: 0.5370>>>myCallback:on_epoch_end 130\n",
      "56/56 [==============================] - 0s 976us/step - loss: 0.6953 - accuracy: 0.5357\n",
      "Epoch 132/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6909 - accuracy: 0.5385>>>myCallback:on_epoch_end 131\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 133/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6914 - accuracy: 0.5400>>>myCallback:on_epoch_end 132\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 134/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6919 - accuracy: 0.5370>>>myCallback:on_epoch_end 133\n",
      "56/56 [==============================] - 0s 948us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 135/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6903 - accuracy: 0.5472>>>myCallback:on_epoch_end 134\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 136/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6929 - accuracy: 0.5306>>>myCallback:on_epoch_end 135\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 137/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6915 - accuracy: 0.5385>>>myCallback:on_epoch_end 136\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 138/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6957 - accuracy: 0.5185    >>>myCallback:on_epoch_end 137\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 139/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6925 - accuracy: 0.5283>>>myCallback:on_epoch_end 138\n",
      "56/56 [==============================] - 0s 967us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 140/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6942 - accuracy: 0.5294>>>myCallback:on_epoch_end 139\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 141/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6841 - accuracy: 0.5882    >>>myCallback:on_epoch_end 140\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6948 - accuracy: 0.5357\n",
      "Epoch 142/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6976 - accuracy: 0.5000    >>>myCallback:on_epoch_end 141\n",
      "56/56 [==============================] - 0s 991us/step - loss: 0.6938 - accuracy: 0.5357\n",
      "Epoch 143/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6934 - accuracy: 0.5294>>>myCallback:on_epoch_end 142\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 144/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6881 - accuracy: 0.5577>>>myCallback:on_epoch_end 143\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 145/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6939 - accuracy: 0.5208>>>myCallback:on_epoch_end 144\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 146/700\n",
      "46/56 [=======================>......] - ETA: 0s - loss: 0.6898 - accuracy: 0.5435    >>>myCallback:on_epoch_end 145\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5357\n",
      "Epoch 147/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6910 - accuracy: 0.5417    >>>myCallback:on_epoch_end 146\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 148/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6923 - accuracy: 0.5294>>>myCallback:on_epoch_end 147\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 149/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.5370>>>myCallback:on_epoch_end 148\n",
      "56/56 [==============================] - 0s 957us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 150/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7788 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 149\n",
      "56/56 [==============================] - 0s 927us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 151/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5283>>>myCallback:on_epoch_end 150\n",
      "56/56 [==============================] - 0s 966us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 152/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6943 - accuracy: 0.5283>>>myCallback:on_epoch_end 151\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 153/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6947 - accuracy: 0.5385    >>>myCallback:on_epoch_end 152\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6947 - accuracy: 0.5357\n",
      "Epoch 154/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6890 - accuracy: 0.5577    >>>myCallback:on_epoch_end 153\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 155/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6927 - accuracy: 0.5283>>>myCallback:on_epoch_end 154\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 156/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6921 - accuracy: 0.5385    >>>myCallback:on_epoch_end 155\n",
      "56/56 [==============================] - 0s 997us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 157/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6942 - accuracy: 0.5283    >>>myCallback:on_epoch_end 156\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 158/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6919 - accuracy: 0.5370>>>myCallback:on_epoch_end 157\n",
      "56/56 [==============================] - 0s 967us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 159/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6926 - accuracy: 0.5283    >>>myCallback:on_epoch_end 158\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 160/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6911 - accuracy: 0.5370>>>myCallback:on_epoch_end 159\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 161/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6947 - accuracy: 0.5185    >>>myCallback:on_epoch_end 160\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 162/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6900 - accuracy: 0.5472>>>myCallback:on_epoch_end 161\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 163/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6935 - accuracy: 0.5283>>>myCallback:on_epoch_end 162\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 164/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6892 - accuracy: 0.5490>>>myCallback:on_epoch_end 163\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 165/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6917 - accuracy: 0.5385>>>myCallback:on_epoch_end 164\n",
      "56/56 [==============================] - 0s 985us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 166/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6910 - accuracy: 0.5370>>>myCallback:on_epoch_end 165\n",
      "56/56 [==============================] - 0s 977us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 167/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6927 - accuracy: 0.5294    >>>myCallback:on_epoch_end 166\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 168/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6907 - accuracy: 0.5385>>>myCallback:on_epoch_end 167\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6911 - accuracy: 0.5357\n",
      "Epoch 169/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6901 - accuracy: 0.5490    >>>myCallback:on_epoch_end 168\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 170/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6922 - accuracy: 0.5472    >>>myCallback:on_epoch_end 169\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6941 - accuracy: 0.5357\n",
      "Epoch 171/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6911 - accuracy: 0.5385    >>>myCallback:on_epoch_end 170\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 172/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6910 - accuracy: 0.5577>>>myCallback:on_epoch_end 171\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5357\n",
      "Epoch 173/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5273    >>>myCallback:on_epoch_end 172\n",
      "56/56 [==============================] - 0s 959us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 174/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.5455    >>>myCallback:on_epoch_end 173\n",
      "56/56 [==============================] - 0s 938us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 175/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6938 - accuracy: 0.5273>>>myCallback:on_epoch_end 174\n",
      "56/56 [==============================] - 0s 931us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 176/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6943 - accuracy: 0.5273>>>myCallback:on_epoch_end 175\n",
      "56/56 [==============================] - 0s 959us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 177/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6965 - accuracy: 0.5192>>>myCallback:on_epoch_end 176\n",
      "56/56 [==============================] - 0s 985us/step - loss: 0.6939 - accuracy: 0.5357\n",
      "Epoch 178/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6929 - accuracy: 0.5370>>>myCallback:on_epoch_end 177\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 179/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6939 - accuracy: 0.5283    >>>myCallback:on_epoch_end 178\n",
      "56/56 [==============================] - 0s 975us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 180/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6885 - accuracy: 0.5556    >>>myCallback:on_epoch_end 179\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 181/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.5455    >>>myCallback:on_epoch_end 180\n",
      "56/56 [==============================] - 0s 948us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 182/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6944 - accuracy: 0.5185    >>>myCallback:on_epoch_end 181\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 183/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6908 - accuracy: 0.5370    >>>myCallback:on_epoch_end 182\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6909 - accuracy: 0.5357\n",
      "Epoch 184/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6913 - accuracy: 0.5385    >>>myCallback:on_epoch_end 183\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 185/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6937 - accuracy: 0.5192    >>>myCallback:on_epoch_end 184\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 186/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6895 - accuracy: 0.5556    >>>myCallback:on_epoch_end 185\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 187/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6945 - accuracy: 0.5192>>>myCallback:on_epoch_end 186\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 188/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6949 - accuracy: 0.5472>>>myCallback:on_epoch_end 187\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6962 - accuracy: 0.5357\n",
      "Epoch 189/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.5370    >>>myCallback:on_epoch_end 188\n",
      "56/56 [==============================] - 0s 956us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 190/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6885 - accuracy: 0.5577    >>>myCallback:on_epoch_end 189\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 191/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6895 - accuracy: 0.5577>>>myCallback:on_epoch_end 190\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 192/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6904 - accuracy: 0.5490    >>>myCallback:on_epoch_end 191\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 193/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5283    >>>myCallback:on_epoch_end 192\n",
      "56/56 [==============================] - 0s 977us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 194/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6963 - accuracy: 0.5098    >>>myCallback:on_epoch_end 193\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 195/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6947 - accuracy: 0.5283    >>>myCallback:on_epoch_end 194\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 196/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6931 - accuracy: 0.5385>>>myCallback:on_epoch_end 195\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 197/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6929 - accuracy: 0.5283    >>>myCallback:on_epoch_end 196\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 198/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6957 - accuracy: 0.5094>>>myCallback:on_epoch_end 197\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 199/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6939 - accuracy: 0.5192>>>myCallback:on_epoch_end 198\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 200/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6935 - accuracy: 0.5283    >>>myCallback:on_epoch_end 199\n",
      "56/56 [==============================] - 0s 966us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 201/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6915 - accuracy: 0.5472    >>>myCallback:on_epoch_end 200\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 202/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6920 - accuracy: 0.5385    >>>myCallback:on_epoch_end 201\n",
      "56/56 [==============================] - 0s 1000us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 203/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6956 - accuracy: 0.5192>>>myCallback:on_epoch_end 202\n",
      "56/56 [==============================] - 0s 997us/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 204/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6910 - accuracy: 0.5370    >>>myCallback:on_epoch_end 203\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 205/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6968 - accuracy: 0.5094    >>>myCallback:on_epoch_end 204\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 206/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6978 - accuracy: 0.5094>>>myCallback:on_epoch_end 205\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6943 - accuracy: 0.5357\n",
      "Epoch 207/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6923 - accuracy: 0.5385    >>>myCallback:on_epoch_end 206\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 208/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6958 - accuracy: 0.5192    >>>myCallback:on_epoch_end 207\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 209/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6908 - accuracy: 0.5472    >>>myCallback:on_epoch_end 208\n",
      "56/56 [==============================] - 0s 987us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 210/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.5283>>>myCallback:on_epoch_end 209\n",
      "56/56 [==============================] - 0s 975us/step - loss: 0.6944 - accuracy: 0.5357\n",
      "Epoch 211/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6924 - accuracy: 0.5385    >>>myCallback:on_epoch_end 210\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 212/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6965 - accuracy: 0.5094>>>myCallback:on_epoch_end 211\n",
      "56/56 [==============================] - 0s 994us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 213/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6927 - accuracy: 0.5294    >>>myCallback:on_epoch_end 212\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 214/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6915 - accuracy: 0.5385    >>>myCallback:on_epoch_end 213\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 215/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6937 - accuracy: 0.5283    >>>myCallback:on_epoch_end 214\n",
      "56/56 [==============================] - 0s 987us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 216/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5357    >>>myCallback:on_epoch_end 215\n",
      "56/56 [==============================] - 0s 930us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 217/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.5472    >>>myCallback:on_epoch_end 216\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 218/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6899 - accuracy: 0.5490>>>myCallback:on_epoch_end 217\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 219/700\n",
      "47/56 [========================>.....] - ETA: 0s - loss: 0.6973 - accuracy: 0.5106    >>>myCallback:on_epoch_end 218\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5357\n",
      "Epoch 220/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6899 - accuracy: 0.5472>>>myCallback:on_epoch_end 219\n",
      "56/56 [==============================] - 0s 987us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 221/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6922 - accuracy: 0.5370    >>>myCallback:on_epoch_end 220\n",
      "56/56 [==============================] - 0s 976us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 222/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5370    >>>myCallback:on_epoch_end 221\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 223/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6844 - accuracy: 0.5769    >>>myCallback:on_epoch_end 222\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 224/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6856 - accuracy: 0.5686>>>myCallback:on_epoch_end 223\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5357\n",
      "Epoch 225/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6903 - accuracy: 0.5472    >>>myCallback:on_epoch_end 224\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 226/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6973 - accuracy: 0.5000>>>myCallback:on_epoch_end 225\n",
      "56/56 [==============================] - 0s 993us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 227/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5273>>>myCallback:on_epoch_end 226\n",
      "56/56 [==============================] - 0s 938us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 228/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6938 - accuracy: 0.5283>>>myCallback:on_epoch_end 227\n",
      "56/56 [==============================] - 0s 995us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 229/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6901 - accuracy: 0.5490>>>myCallback:on_epoch_end 228\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 230/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6923 - accuracy: 0.5294>>>myCallback:on_epoch_end 229\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 231/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6953 - accuracy: 0.5192    >>>myCallback:on_epoch_end 230\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 232/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6885 - accuracy: 0.5577>>>myCallback:on_epoch_end 231\n",
      "56/56 [==============================] - 0s 997us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 233/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6942 - accuracy: 0.5185>>>myCallback:on_epoch_end 232\n",
      "56/56 [==============================] - 0s 986us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 234/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6951 - accuracy: 0.5283>>>myCallback:on_epoch_end 233\n",
      "56/56 [==============================] - 0s 985us/step - loss: 0.6939 - accuracy: 0.5357\n",
      "Epoch 235/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6984 - accuracy: 0.4898>>>myCallback:on_epoch_end 234\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 236/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6933 - accuracy: 0.5200    >>>myCallback:on_epoch_end 235\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5357\n",
      "Epoch 237/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6953 - accuracy: 0.5417>>>myCallback:on_epoch_end 236\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.5357\n",
      "Epoch 238/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6987 - accuracy: 0.5000    >>>myCallback:on_epoch_end 237\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5357\n",
      "Epoch 239/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6919 - accuracy: 0.5385    >>>myCallback:on_epoch_end 238\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 240/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6935 - accuracy: 0.5283    >>>myCallback:on_epoch_end 239\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 241/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6942 - accuracy: 0.5192    >>>myCallback:on_epoch_end 240\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 242/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6966 - accuracy: 0.5000    >>>myCallback:on_epoch_end 241\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 243/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6927 - accuracy: 0.5385>>>myCallback:on_epoch_end 242\n",
      "56/56 [==============================] - 0s 995us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 244/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6968 - accuracy: 0.5192    >>>myCallback:on_epoch_end 243\n",
      "56/56 [==============================] - 0s 991us/step - loss: 0.6948 - accuracy: 0.5357\n",
      "Epoch 245/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6949 - accuracy: 0.5283>>>myCallback:on_epoch_end 244\n",
      "56/56 [==============================] - 0s 974us/step - loss: 0.6937 - accuracy: 0.5357\n",
      "Epoch 246/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6946 - accuracy: 0.5283>>>myCallback:on_epoch_end 245\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 247/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.5472>>>myCallback:on_epoch_end 246\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 248/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6952 - accuracy: 0.5273>>>myCallback:on_epoch_end 247\n",
      "56/56 [==============================] - 0s 928us/step - loss: 0.6943 - accuracy: 0.5357\n",
      "Epoch 249/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5357>>>myCallback:on_epoch_end 248\n",
      "56/56 [==============================] - 0s 924us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 250/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6903 - accuracy: 0.5556    >>>myCallback:on_epoch_end 249\n",
      "56/56 [==============================] - 0s 968us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 251/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.5273>>>myCallback:on_epoch_end 250\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 252/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6889 - accuracy: 0.5600>>>myCallback:on_epoch_end 251\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 253/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6926 - accuracy: 0.5400    >>>myCallback:on_epoch_end 252\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 254/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.5294    >>>myCallback:on_epoch_end 253\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 255/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6947 - accuracy: 0.5306    >>>myCallback:on_epoch_end 254\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 256/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6922 - accuracy: 0.5306    >>>myCallback:on_epoch_end 255\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 257/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6926 - accuracy: 0.5294>>>myCallback:on_epoch_end 256\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 258/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6983 - accuracy: 0.4902>>>myCallback:on_epoch_end 257\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5357\n",
      "Epoch 259/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.5370    >>>myCallback:on_epoch_end 258\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 260/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7629 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 259\n",
      "56/56 [==============================] - 0s 908us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 261/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.5472>>>myCallback:on_epoch_end 260\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 262/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6878 - accuracy: 0.5686    >>>myCallback:on_epoch_end 261\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 263/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6940 - accuracy: 0.5273    >>>myCallback:on_epoch_end 262\n",
      "56/56 [==============================] - 0s 960us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 264/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5370>>>myCallback:on_epoch_end 263\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 265/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6922 - accuracy: 0.5370    >>>myCallback:on_epoch_end 264\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 266/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6910 - accuracy: 0.5472    >>>myCallback:on_epoch_end 265\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 267/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6937 - accuracy: 0.5185>>>myCallback:on_epoch_end 266\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 268/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.5357>>>myCallback:on_epoch_end 267\n",
      "56/56 [==============================] - 0s 938us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 269/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6282 - accuracy: 1.0000>>>myCallback:on_epoch_end 268\n",
      "56/56 [==============================] - 0s 906us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 270/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6945 - accuracy: 0.5185>>>myCallback:on_epoch_end 269\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 271/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6908 - accuracy: 0.5400    >>>myCallback:on_epoch_end 270\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 272/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5283    >>>myCallback:on_epoch_end 271\n",
      "56/56 [==============================] - 0s 993us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 273/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6908 - accuracy: 0.5472>>>myCallback:on_epoch_end 272\n",
      "56/56 [==============================] - 0s 966us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 274/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6897 - accuracy: 0.5472>>>myCallback:on_epoch_end 273\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 275/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5357    >>>myCallback:on_epoch_end 274\n",
      "56/56 [==============================] - 0s 913us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 276/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5357>>>myCallback:on_epoch_end 275\n",
      "56/56 [==============================] - 0s 919us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 277/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6967 - accuracy: 0.5185>>>myCallback:on_epoch_end 276\n",
      "56/56 [==============================] - 0s 955us/step - loss: 0.6939 - accuracy: 0.5357\n",
      "Epoch 278/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6913 - accuracy: 0.5370    >>>myCallback:on_epoch_end 277\n",
      "56/56 [==============================] - 0s 960us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 279/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6947 - accuracy: 0.5192>>>myCallback:on_epoch_end 278\n",
      "56/56 [==============================] - 0s 985us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 280/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6906 - accuracy: 0.5577    >>>myCallback:on_epoch_end 279\n",
      "56/56 [==============================] - 0s 986us/step - loss: 0.6944 - accuracy: 0.5357\n",
      "Epoch 281/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6873 - accuracy: 0.5660>>>myCallback:on_epoch_end 280\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 282/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5273    >>>myCallback:on_epoch_end 281\n",
      "56/56 [==============================] - 0s 954us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 283/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6917 - accuracy: 0.5455>>>myCallback:on_epoch_end 282\n",
      "56/56 [==============================] - 0s 937us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 284/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5357    >>>myCallback:on_epoch_end 283\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 285/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5273>>>myCallback:on_epoch_end 284\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 286/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6890 - accuracy: 0.5556    >>>myCallback:on_epoch_end 285\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 287/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5283>>>myCallback:on_epoch_end 286\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 288/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.5094>>>myCallback:on_epoch_end 287\n",
      "56/56 [==============================] - 0s 979us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 289/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6938 - accuracy: 0.5200    >>>myCallback:on_epoch_end 288\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 290/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6951 - accuracy: 0.5098    >>>myCallback:on_epoch_end 289\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 291/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6891 - accuracy: 0.5577>>>myCallback:on_epoch_end 290\n",
      "56/56 [==============================] - 0s 992us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 292/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6880 - accuracy: 0.5686>>>myCallback:on_epoch_end 291\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 293/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6920 - accuracy: 0.5385>>>myCallback:on_epoch_end 292\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 294/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6889 - accuracy: 0.5556>>>myCallback:on_epoch_end 293\n",
      "56/56 [==============================] - 0s 977us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 295/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.5094>>>myCallback:on_epoch_end 294\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 296/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.5472>>>myCallback:on_epoch_end 295\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 297/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6983 - accuracy: 0.5000    >>>myCallback:on_epoch_end 296\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5357\n",
      "Epoch 298/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6899 - accuracy: 0.5490    >>>myCallback:on_epoch_end 297\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 299/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6936 - accuracy: 0.5208    >>>myCallback:on_epoch_end 298\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 300/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5357    >>>myCallback:on_epoch_end 299\n",
      "56/56 [==============================] - 0s 935us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 301/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6926 - accuracy: 0.5294    >>>myCallback:on_epoch_end 300\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 302/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6887 - accuracy: 0.5556>>>myCallback:on_epoch_end 301\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 303/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6924 - accuracy: 0.5472>>>myCallback:on_epoch_end 302\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 304/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.5455    >>>myCallback:on_epoch_end 303\n",
      "56/56 [==============================] - 0s 949us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 305/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6902 - accuracy: 0.5455>>>myCallback:on_epoch_end 304\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 306/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6918 - accuracy: 0.5370>>>myCallback:on_epoch_end 305\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 307/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5370>>>myCallback:on_epoch_end 306\n",
      "56/56 [==============================] - 0s 958us/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 308/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6293 - accuracy: 1.0000>>>myCallback:on_epoch_end 307\n",
      "56/56 [==============================] - 0s 924us/step - loss: 0.6938 - accuracy: 0.5357\n",
      "Epoch 309/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.5273    >>>myCallback:on_epoch_end 308\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 310/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5273>>>myCallback:on_epoch_end 309\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 311/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6919 - accuracy: 0.5455>>>myCallback:on_epoch_end 310\n",
      "56/56 [==============================] - 0s 932us/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 312/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.5357    >>>myCallback:on_epoch_end 311\n",
      "56/56 [==============================] - 0s 923us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 313/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.5455    >>>myCallback:on_epoch_end 312\n",
      "56/56 [==============================] - 0s 930us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 314/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.5455    >>>myCallback:on_epoch_end 313\n",
      "56/56 [==============================] - 0s 968us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 315/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5273>>>myCallback:on_epoch_end 314\n",
      "56/56 [==============================] - 0s 948us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 316/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.5273>>>myCallback:on_epoch_end 315\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 317/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6904 - accuracy: 0.5455    >>>myCallback:on_epoch_end 316\n",
      "56/56 [==============================] - 0s 955us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 318/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.5455    >>>myCallback:on_epoch_end 317\n",
      "56/56 [==============================] - 0s 949us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 319/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5273    >>>myCallback:on_epoch_end 318\n",
      "56/56 [==============================] - 0s 950us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 320/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.5472>>>myCallback:on_epoch_end 319\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 321/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.5273    >>>myCallback:on_epoch_end 320\n",
      "56/56 [==============================] - 0s 955us/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 322/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.5370>>>myCallback:on_epoch_end 321\n",
      "56/56 [==============================] - 0s 967us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 323/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6910 - accuracy: 0.5370>>>myCallback:on_epoch_end 322\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 324/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5357>>>myCallback:on_epoch_end 323\n",
      "56/56 [==============================] - 0s 937us/step - loss: 0.6939 - accuracy: 0.5357\n",
      "Epoch 325/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6955 - accuracy: 0.5094    >>>myCallback:on_epoch_end 324\n",
      "56/56 [==============================] - 0s 966us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 326/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6903 - accuracy: 0.5455    >>>myCallback:on_epoch_end 325\n",
      "56/56 [==============================] - 0s 942us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 327/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6929 - accuracy: 0.5283    >>>myCallback:on_epoch_end 326\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 328/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6251 - accuracy: 1.0000>>>myCallback:on_epoch_end 327\n",
      "56/56 [==============================] - 0s 899us/step - loss: 0.6942 - accuracy: 0.5357\n",
      "Epoch 329/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.5455>>>myCallback:on_epoch_end 328\n",
      "56/56 [==============================] - 0s 947us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 330/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5357>>>myCallback:on_epoch_end 329\n",
      "56/56 [==============================] - 0s 943us/step - loss: 0.6937 - accuracy: 0.5357\n",
      "Epoch 331/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5357    >>>myCallback:on_epoch_end 330\n",
      "56/56 [==============================] - 0s 936us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 332/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5357>>>myCallback:on_epoch_end 331\n",
      "56/56 [==============================] - 0s 911us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 333/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5357    >>>myCallback:on_epoch_end 332\n",
      "56/56 [==============================] - 0s 930us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 334/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5273>>>myCallback:on_epoch_end 333\n",
      "56/56 [==============================] - 0s 938us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 335/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5357>>>myCallback:on_epoch_end 334\n",
      "56/56 [==============================] - 0s 915us/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 336/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.5455    >>>myCallback:on_epoch_end 335\n",
      "56/56 [==============================] - 0s 943us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 337/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5357    >>>myCallback:on_epoch_end 336\n",
      "56/56 [==============================] - 0s 933us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 338/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5357    >>>myCallback:on_epoch_end 337\n",
      "56/56 [==============================] - 0s 927us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 339/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5357>>>myCallback:on_epoch_end 338\n",
      "56/56 [==============================] - 0s 924us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 340/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6945 - accuracy: 0.5283>>>myCallback:on_epoch_end 339\n",
      "56/56 [==============================] - 0s 968us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 341/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6910 - accuracy: 0.5455    >>>myCallback:on_epoch_end 340\n",
      "56/56 [==============================] - 0s 933us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 342/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6898 - accuracy: 0.5455>>>myCallback:on_epoch_end 341\n",
      "56/56 [==============================] - 0s 945us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 343/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6898 - accuracy: 0.5455>>>myCallback:on_epoch_end 342\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 344/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5357>>>myCallback:on_epoch_end 343\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 345/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5357>>>myCallback:on_epoch_end 344\n",
      "56/56 [==============================] - 0s 928us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 346/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.5357>>>myCallback:on_epoch_end 345\n",
      "56/56 [==============================] - 0s 945us/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 347/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6894 - accuracy: 0.5556>>>myCallback:on_epoch_end 346\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 348/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.5273>>>myCallback:on_epoch_end 347\n",
      "56/56 [==============================] - 0s 941us/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 349/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6940 - accuracy: 0.5185    >>>myCallback:on_epoch_end 348\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 350/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5283>>>myCallback:on_epoch_end 349\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 351/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5357    >>>myCallback:on_epoch_end 350\n",
      "56/56 [==============================] - 0s 926us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 352/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6914 - accuracy: 0.5370    >>>myCallback:on_epoch_end 351\n",
      "56/56 [==============================] - 0s 951us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 353/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6940 - accuracy: 0.5370>>>myCallback:on_epoch_end 352\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 354/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6904 - accuracy: 0.5472>>>myCallback:on_epoch_end 353\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 355/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6909 - accuracy: 0.5490>>>myCallback:on_epoch_end 354\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 356/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6945 - accuracy: 0.5185>>>myCallback:on_epoch_end 355\n",
      "56/56 [==============================] - 0s 948us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 357/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6914 - accuracy: 0.5370>>>myCallback:on_epoch_end 356\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 358/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6884 - accuracy: 0.5577>>>myCallback:on_epoch_end 357\n",
      "56/56 [==============================] - 0s 996us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 359/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6897 - accuracy: 0.5472    >>>myCallback:on_epoch_end 358\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 360/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6926 - accuracy: 0.5472>>>myCallback:on_epoch_end 359\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6941 - accuracy: 0.5357\n",
      "Epoch 361/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6909 - accuracy: 0.5556>>>myCallback:on_epoch_end 360\n",
      "56/56 [==============================] - 0s 979us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 362/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6925 - accuracy: 0.5370>>>myCallback:on_epoch_end 361\n",
      "56/56 [==============================] - 0s 966us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 363/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6900 - accuracy: 0.5455>>>myCallback:on_epoch_end 362\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 364/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5357    >>>myCallback:on_epoch_end 363\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 365/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6932 - accuracy: 0.5370>>>myCallback:on_epoch_end 364\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 366/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6908 - accuracy: 0.5472>>>myCallback:on_epoch_end 365\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 367/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5273>>>myCallback:on_epoch_end 366\n",
      "56/56 [==============================] - 0s 948us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 368/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6946 - accuracy: 0.5185    >>>myCallback:on_epoch_end 367\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 369/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6882 - accuracy: 0.5577>>>myCallback:on_epoch_end 368\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 370/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.5370    >>>myCallback:on_epoch_end 369\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 371/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6935 - accuracy: 0.5192>>>myCallback:on_epoch_end 370\n",
      "56/56 [==============================] - 0s 1000us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 372/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6935 - accuracy: 0.5283    >>>myCallback:on_epoch_end 371\n",
      "56/56 [==============================] - 0s 990us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 373/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5357>>>myCallback:on_epoch_end 372\n",
      "56/56 [==============================] - 0s 947us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 374/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6925 - accuracy: 0.5283    >>>myCallback:on_epoch_end 373\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 375/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5357    >>>myCallback:on_epoch_end 374\n",
      "56/56 [==============================] - 0s 927us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 376/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5357>>>myCallback:on_epoch_end 375\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 377/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6903 - accuracy: 0.5455    >>>myCallback:on_epoch_end 376\n",
      "56/56 [==============================] - 0s 945us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 378/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5273>>>myCallback:on_epoch_end 377\n",
      "56/56 [==============================] - 0s 941us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 379/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6877 - accuracy: 0.5769    >>>myCallback:on_epoch_end 378\n",
      "56/56 [==============================] - 0s 997us/step - loss: 0.6958 - accuracy: 0.5357\n",
      "Epoch 380/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6892 - accuracy: 0.5660    >>>myCallback:on_epoch_end 379\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 381/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6957 - accuracy: 0.5185    >>>myCallback:on_epoch_end 380\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 382/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6886 - accuracy: 0.5556    >>>myCallback:on_epoch_end 381\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 383/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.5370>>>myCallback:on_epoch_end 382\n",
      "56/56 [==============================] - 0s 967us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 384/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5273>>>myCallback:on_epoch_end 383\n",
      "56/56 [==============================] - 0s 928us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 385/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7632 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 384\n",
      "56/56 [==============================] - 0s 904us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 386/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.5357>>>myCallback:on_epoch_end 385\n",
      "56/56 [==============================] - 0s 935us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 387/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6898 - accuracy: 0.5472>>>myCallback:on_epoch_end 386\n",
      "56/56 [==============================] - 0s 973us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 388/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6144 - accuracy: 1.0000>>>myCallback:on_epoch_end 387\n",
      "56/56 [==============================] - 0s 891us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 389/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.5357>>>myCallback:on_epoch_end 388\n",
      "56/56 [==============================] - 0s 928us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 390/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6939 - accuracy: 0.5185>>>myCallback:on_epoch_end 389\n",
      "56/56 [==============================] - 0s 946us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 391/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5357>>>myCallback:on_epoch_end 390\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 392/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6877 - accuracy: 0.5660    >>>myCallback:on_epoch_end 391\n",
      "56/56 [==============================] - 0s 968us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 393/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6935 - accuracy: 0.5273>>>myCallback:on_epoch_end 392\n",
      "56/56 [==============================] - 0s 959us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 394/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5273>>>myCallback:on_epoch_end 393\n",
      "56/56 [==============================] - 0s 959us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 395/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6938 - accuracy: 0.5192    >>>myCallback:on_epoch_end 394\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 396/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5273>>>myCallback:on_epoch_end 395\n",
      "56/56 [==============================] - 0s 953us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 397/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5283>>>myCallback:on_epoch_end 396\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 398/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6895 - accuracy: 0.5577>>>myCallback:on_epoch_end 397\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 399/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.5370    >>>myCallback:on_epoch_end 398\n",
      "56/56 [==============================] - 0s 968us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 400/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6950 - accuracy: 0.5094>>>myCallback:on_epoch_end 399\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 401/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.5455    >>>myCallback:on_epoch_end 400\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 402/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5283>>>myCallback:on_epoch_end 401\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 403/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6901 - accuracy: 0.5490>>>myCallback:on_epoch_end 402\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 404/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6941 - accuracy: 0.5185    >>>myCallback:on_epoch_end 403\n",
      "56/56 [==============================] - 0s 956us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 405/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6918 - accuracy: 0.5370    >>>myCallback:on_epoch_end 404\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 406/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.5357>>>myCallback:on_epoch_end 405\n",
      "56/56 [==============================] - 0s 922us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 407/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6931 - accuracy: 0.5273    >>>myCallback:on_epoch_end 406\n",
      "56/56 [==============================] - 0s 937us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 408/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6913 - accuracy: 0.5357    >>>myCallback:on_epoch_end 407\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 409/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6892 - accuracy: 0.5556    >>>myCallback:on_epoch_end 408\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 410/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6875 - accuracy: 0.5600    >>>myCallback:on_epoch_end 409\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 411/700\n",
      "47/56 [========================>.....] - ETA: 0s - loss: 0.6857 - accuracy: 0.5745>>>myCallback:on_epoch_end 410\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 412/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6916 - accuracy: 0.5417    >>>myCallback:on_epoch_end 411\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 413/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6926 - accuracy: 0.5306>>>myCallback:on_epoch_end 412\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 414/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.5472>>>myCallback:on_epoch_end 413\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 415/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6918 - accuracy: 0.5385    >>>myCallback:on_epoch_end 414\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 416/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6933 - accuracy: 0.5294    >>>myCallback:on_epoch_end 415\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 417/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6867 - accuracy: 0.5660    >>>myCallback:on_epoch_end 416\n",
      "56/56 [==============================] - 0s 993us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 418/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6936 - accuracy: 0.5192>>>myCallback:on_epoch_end 417\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 419/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6975 - accuracy: 0.5000    >>>myCallback:on_epoch_end 418\n",
      "56/56 [==============================] - 0s 991us/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 420/700\n",
      "47/56 [========================>.....] - ETA: 0s - loss: 0.6956 - accuracy: 0.5106    >>>myCallback:on_epoch_end 419\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 421/700\n",
      "47/56 [========================>.....] - ETA: 0s - loss: 0.6889 - accuracy: 0.5532    >>>myCallback:on_epoch_end 420\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 422/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6902 - accuracy: 0.5510    >>>myCallback:on_epoch_end 421\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 423/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.5294>>>myCallback:on_epoch_end 422\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 424/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.5370    >>>myCallback:on_epoch_end 423\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 425/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6869 - accuracy: 0.5660    >>>myCallback:on_epoch_end 424\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 426/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6950 - accuracy: 0.5192>>>myCallback:on_epoch_end 425\n",
      "56/56 [==============================] - 0s 994us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 427/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.5283    >>>myCallback:on_epoch_end 426\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6911 - accuracy: 0.5357\n",
      "Epoch 428/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6959 - accuracy: 0.5098>>>myCallback:on_epoch_end 427\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 429/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6894 - accuracy: 0.5510    >>>myCallback:on_epoch_end 428\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 430/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6944 - accuracy: 0.5208    >>>myCallback:on_epoch_end 429\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 431/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6944 - accuracy: 0.5400>>>myCallback:on_epoch_end 430\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5357\n",
      "Epoch 432/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6895 - accuracy: 0.5600>>>myCallback:on_epoch_end 431\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 433/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6924 - accuracy: 0.5294    >>>myCallback:on_epoch_end 432\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 434/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6918 - accuracy: 0.5472>>>myCallback:on_epoch_end 433\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 435/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6963 - accuracy: 0.5192    >>>myCallback:on_epoch_end 434\n",
      "56/56 [==============================] - 0s 986us/step - loss: 0.6939 - accuracy: 0.5357\n",
      "Epoch 436/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6937 - accuracy: 0.5192>>>myCallback:on_epoch_end 435\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 437/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6955 - accuracy: 0.5283    >>>myCallback:on_epoch_end 436\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6944 - accuracy: 0.5357\n",
      "Epoch 438/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6940 - accuracy: 0.5370    >>>myCallback:on_epoch_end 437\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 439/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6923 - accuracy: 0.5294>>>myCallback:on_epoch_end 438\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 440/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6961 - accuracy: 0.5098>>>myCallback:on_epoch_end 439\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 441/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6929 - accuracy: 0.5283    >>>myCallback:on_epoch_end 440\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 442/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6950 - accuracy: 0.5400>>>myCallback:on_epoch_end 441\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6950 - accuracy: 0.5357\n",
      "Epoch 443/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6918 - accuracy: 0.5417    >>>myCallback:on_epoch_end 442\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 444/700\n",
      "47/56 [========================>.....] - ETA: 0s - loss: 0.6971 - accuracy: 0.5106    >>>myCallback:on_epoch_end 443\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 445/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6934 - accuracy: 0.5400    >>>myCallback:on_epoch_end 444\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5357\n",
      "Epoch 446/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6866 - accuracy: 0.5686    >>>myCallback:on_epoch_end 445\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 447/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6927 - accuracy: 0.5283    >>>myCallback:on_epoch_end 446\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 448/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6926 - accuracy: 0.5370    >>>myCallback:on_epoch_end 447\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 449/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6878 - accuracy: 0.5577>>>myCallback:on_epoch_end 448\n",
      "56/56 [==============================] - 0s 994us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 450/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6945 - accuracy: 0.5283    >>>myCallback:on_epoch_end 449\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 451/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5273>>>myCallback:on_epoch_end 450\n",
      "56/56 [==============================] - 0s 952us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 452/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6990 - accuracy: 0.4902    >>>myCallback:on_epoch_end 451\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 453/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6916 - accuracy: 0.5306    >>>myCallback:on_epoch_end 452\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5357\n",
      "Epoch 454/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6863 - accuracy: 0.5714    >>>myCallback:on_epoch_end 453\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 455/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6957 - accuracy: 0.5102>>>myCallback:on_epoch_end 454\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 456/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6807 - accuracy: 0.6042    >>>myCallback:on_epoch_end 455\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5357\n",
      "Epoch 457/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6888 - accuracy: 0.5556>>>myCallback:on_epoch_end 456\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 458/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6907 - accuracy: 0.5455>>>myCallback:on_epoch_end 457\n",
      "56/56 [==============================] - 0s 953us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 459/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6942 - accuracy: 0.5192    >>>myCallback:on_epoch_end 458\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 460/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6911 - accuracy: 0.5370    >>>myCallback:on_epoch_end 459\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 461/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6947 - accuracy: 0.5283>>>myCallback:on_epoch_end 460\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 462/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6870 - accuracy: 0.5714>>>myCallback:on_epoch_end 461\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 463/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6948 - accuracy: 0.5192    >>>myCallback:on_epoch_end 462\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 464/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6898 - accuracy: 0.5510>>>myCallback:on_epoch_end 463\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 465/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6883 - accuracy: 0.5600>>>myCallback:on_epoch_end 464\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 466/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6961 - accuracy: 0.5000>>>myCallback:on_epoch_end 465\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 467/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6942 - accuracy: 0.5294>>>myCallback:on_epoch_end 466\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 468/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6901 - accuracy: 0.5490>>>myCallback:on_epoch_end 467\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 469/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6941 - accuracy: 0.5185    >>>myCallback:on_epoch_end 468\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 470/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6934 - accuracy: 0.5283    >>>myCallback:on_epoch_end 469\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 471/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6904 - accuracy: 0.5472    >>>myCallback:on_epoch_end 470\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 472/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6927 - accuracy: 0.5283    >>>myCallback:on_epoch_end 471\n",
      "56/56 [==============================] - 0s 996us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 473/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.5185    >>>myCallback:on_epoch_end 472\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 474/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6939 - accuracy: 0.5192    >>>myCallback:on_epoch_end 473\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 475/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6854 - accuracy: 0.5714    >>>myCallback:on_epoch_end 474\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 476/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6905 - accuracy: 0.5417    >>>myCallback:on_epoch_end 475\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 477/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6963 - accuracy: 0.5000>>>myCallback:on_epoch_end 476\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 478/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6936 - accuracy: 0.5306    >>>myCallback:on_epoch_end 477\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 479/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6948 - accuracy: 0.5283    >>>myCallback:on_epoch_end 478\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6937 - accuracy: 0.5357\n",
      "Epoch 480/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6865 - accuracy: 0.5660>>>myCallback:on_epoch_end 479\n",
      "56/56 [==============================] - 0s 987us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 481/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6907 - accuracy: 0.5472    >>>myCallback:on_epoch_end 480\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 482/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6904 - accuracy: 0.5472    >>>myCallback:on_epoch_end 481\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 483/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6906 - accuracy: 0.5455    >>>myCallback:on_epoch_end 482\n",
      "56/56 [==============================] - 0s 957us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 484/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6935 - accuracy: 0.5283    >>>myCallback:on_epoch_end 483\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 485/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6911 - accuracy: 0.5417    >>>myCallback:on_epoch_end 484\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 486/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6906 - accuracy: 0.5417    >>>myCallback:on_epoch_end 485\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 487/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6928 - accuracy: 0.5294    >>>myCallback:on_epoch_end 486\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 488/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6937 - accuracy: 0.5283>>>myCallback:on_epoch_end 487\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 489/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6892 - accuracy: 0.5556    >>>myCallback:on_epoch_end 488\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 490/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6925 - accuracy: 0.5283>>>myCallback:on_epoch_end 489\n",
      "56/56 [==============================] - 0s 977us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 491/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6925 - accuracy: 0.5273>>>myCallback:on_epoch_end 490\n",
      "56/56 [==============================] - 0s 937us/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 492/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6937 - accuracy: 0.5283>>>myCallback:on_epoch_end 491\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 493/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6918 - accuracy: 0.5400>>>myCallback:on_epoch_end 492\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 494/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6941 - accuracy: 0.5192>>>myCallback:on_epoch_end 493\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 495/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6908 - accuracy: 0.5385>>>myCallback:on_epoch_end 494\n",
      "56/56 [==============================] - 0s 995us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 496/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.5472>>>myCallback:on_epoch_end 495\n",
      "56/56 [==============================] - 0s 988us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 497/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6936 - accuracy: 0.5472    >>>myCallback:on_epoch_end 496\n",
      "56/56 [==============================] - 0s 979us/step - loss: 0.6949 - accuracy: 0.5357\n",
      "Epoch 498/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6913 - accuracy: 0.5370>>>myCallback:on_epoch_end 497\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 499/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6912 - accuracy: 0.5455>>>myCallback:on_epoch_end 498\n",
      "56/56 [==============================] - 0s 953us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 500/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6958 - accuracy: 0.5192    >>>myCallback:on_epoch_end 499\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 501/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6958 - accuracy: 0.5200    >>>myCallback:on_epoch_end 500\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 502/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6942 - accuracy: 0.5200    >>>myCallback:on_epoch_end 501\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 503/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6923 - accuracy: 0.5385>>>myCallback:on_epoch_end 502\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 504/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5357>>>myCallback:on_epoch_end 503\n",
      "56/56 [==============================] - 0s 936us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 505/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6157 - accuracy: 1.0000>>>myCallback:on_epoch_end 504\n",
      "56/56 [==============================] - 0s 907us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 506/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6938 - accuracy: 0.5273>>>myCallback:on_epoch_end 505\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 507/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6919 - accuracy: 0.5455    >>>myCallback:on_epoch_end 506\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 508/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7773 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 507\n",
      "56/56 [==============================] - 0s 904us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 509/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5273    >>>myCallback:on_epoch_end 508\n",
      "56/56 [==============================] - 0s 947us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 510/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6910 - accuracy: 0.5577>>>myCallback:on_epoch_end 509\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5357\n",
      "Epoch 511/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6971 - accuracy: 0.5185    >>>myCallback:on_epoch_end 510\n",
      "56/56 [==============================] - 0s 961us/step - loss: 0.6953 - accuracy: 0.5357\n",
      "Epoch 512/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6973 - accuracy: 0.5102>>>myCallback:on_epoch_end 511\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 513/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6895 - accuracy: 0.5510>>>myCallback:on_epoch_end 512\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 514/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6923 - accuracy: 0.5306    >>>myCallback:on_epoch_end 513\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 515/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6925 - accuracy: 0.5472>>>myCallback:on_epoch_end 514\n",
      "56/56 [==============================] - 0s 966us/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 516/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6952 - accuracy: 0.5102>>>myCallback:on_epoch_end 515\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 517/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6942 - accuracy: 0.5192    >>>myCallback:on_epoch_end 516\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 518/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6909 - accuracy: 0.5385>>>myCallback:on_epoch_end 517\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 519/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6951 - accuracy: 0.5094    >>>myCallback:on_epoch_end 518\n",
      "56/56 [==============================] - 0s 987us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 520/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6951 - accuracy: 0.5102    >>>myCallback:on_epoch_end 519\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 521/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6934 - accuracy: 0.5283>>>myCallback:on_epoch_end 520\n",
      "56/56 [==============================] - 0s 990us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 522/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6944 - accuracy: 0.5385>>>myCallback:on_epoch_end 521\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6946 - accuracy: 0.5357\n",
      "Epoch 523/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6946 - accuracy: 0.5577>>>myCallback:on_epoch_end 522\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.5357\n",
      "Epoch 524/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6938 - accuracy: 0.5192    >>>myCallback:on_epoch_end 523\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 525/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6880 - accuracy: 0.5686>>>myCallback:on_epoch_end 524\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 526/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6948 - accuracy: 0.5098>>>myCallback:on_epoch_end 525\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 527/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6926 - accuracy: 0.5294    >>>myCallback:on_epoch_end 526\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 528/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6875 - accuracy: 0.5625    >>>myCallback:on_epoch_end 527\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 529/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6902 - accuracy: 0.5510    >>>myCallback:on_epoch_end 528\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 530/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6944 - accuracy: 0.5098    >>>myCallback:on_epoch_end 529\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5357\n",
      "Epoch 531/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6901 - accuracy: 0.5472>>>myCallback:on_epoch_end 530\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 532/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.5370    >>>myCallback:on_epoch_end 531\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 533/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6889 - accuracy: 0.5577    >>>myCallback:on_epoch_end 532\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 534/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6922 - accuracy: 0.5370    >>>myCallback:on_epoch_end 533\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 535/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6916 - accuracy: 0.5490    >>>myCallback:on_epoch_end 534\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 536/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6919 - accuracy: 0.5472>>>myCallback:on_epoch_end 535\n",
      "56/56 [==============================] - 0s 992us/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 537/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6939 - accuracy: 0.5294    >>>myCallback:on_epoch_end 536\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 538/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6948 - accuracy: 0.5192    >>>myCallback:on_epoch_end 537\n",
      "56/56 [==============================] - 0s 994us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 539/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6940 - accuracy: 0.5294    >>>myCallback:on_epoch_end 538\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 540/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6899 - accuracy: 0.5472    >>>myCallback:on_epoch_end 539\n",
      "56/56 [==============================] - 0s 995us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 541/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6833 - accuracy: 0.5882    >>>myCallback:on_epoch_end 540\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 542/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6904 - accuracy: 0.5556    >>>myCallback:on_epoch_end 541\n",
      "56/56 [==============================] - 0s 988us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 543/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6933 - accuracy: 0.5400    >>>myCallback:on_epoch_end 542\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 544/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6886 - accuracy: 0.5660>>>myCallback:on_epoch_end 543\n",
      "56/56 [==============================] - 0s 995us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 545/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6916 - accuracy: 0.5400    >>>myCallback:on_epoch_end 544\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 546/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6909 - accuracy: 0.5472    >>>myCallback:on_epoch_end 545\n",
      "56/56 [==============================] - 0s 986us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 547/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5283    >>>myCallback:on_epoch_end 546\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 548/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.5294    >>>myCallback:on_epoch_end 547\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 549/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6914 - accuracy: 0.5385    >>>myCallback:on_epoch_end 548\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 550/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6937 - accuracy: 0.5192>>>myCallback:on_epoch_end 549\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 551/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6892 - accuracy: 0.5600>>>myCallback:on_epoch_end 550\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 552/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6835 - accuracy: 0.5882    >>>myCallback:on_epoch_end 551\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 553/700\n",
      "47/56 [========================>.....] - ETA: 0s - loss: 0.6781 - accuracy: 0.6170>>>myCallback:on_epoch_end 552\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 554/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6906 - accuracy: 0.5417>>>myCallback:on_epoch_end 553\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 555/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6892 - accuracy: 0.5600>>>myCallback:on_epoch_end 554\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 556/700\n",
      "47/56 [========================>.....] - ETA: 0s - loss: 0.6985 - accuracy: 0.4681>>>myCallback:on_epoch_end 555\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 557/700\n",
      "46/56 [=======================>......] - ETA: 0s - loss: 0.6913 - accuracy: 0.5435>>>myCallback:on_epoch_end 556\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 558/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6957 - accuracy: 0.5094    >>>myCallback:on_epoch_end 557\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 559/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6886 - accuracy: 0.5660>>>myCallback:on_epoch_end 558\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6938 - accuracy: 0.5357\n",
      "Epoch 560/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6953 - accuracy: 0.5283    >>>myCallback:on_epoch_end 559\n",
      "56/56 [==============================] - 0s 990us/step - loss: 0.6942 - accuracy: 0.5357\n",
      "Epoch 561/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6913 - accuracy: 0.5400>>>myCallback:on_epoch_end 560\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 562/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6910 - accuracy: 0.5385    >>>myCallback:on_epoch_end 561\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 563/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6941 - accuracy: 0.5192    >>>myCallback:on_epoch_end 562\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 564/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6948 - accuracy: 0.5192    >>>myCallback:on_epoch_end 563\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 565/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6935 - accuracy: 0.5294    >>>myCallback:on_epoch_end 564\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 566/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6948 - accuracy: 0.5200    >>>myCallback:on_epoch_end 565\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 567/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6948 - accuracy: 0.5306>>>myCallback:on_epoch_end 566\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 568/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6955 - accuracy: 0.5098    >>>myCallback:on_epoch_end 567\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 569/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6917 - accuracy: 0.5385>>>myCallback:on_epoch_end 568\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 570/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6946 - accuracy: 0.5294>>>myCallback:on_epoch_end 569\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 571/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6970 - accuracy: 0.5000    >>>myCallback:on_epoch_end 570\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 572/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6919 - accuracy: 0.5283>>>myCallback:on_epoch_end 571\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6909 - accuracy: 0.5357\n",
      "Epoch 573/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6977 - accuracy: 0.4902>>>myCallback:on_epoch_end 572\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5357\n",
      "Epoch 574/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6924 - accuracy: 0.5385>>>myCallback:on_epoch_end 573\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 575/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6942 - accuracy: 0.5294>>>myCallback:on_epoch_end 574\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5357\n",
      "Epoch 576/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6921 - accuracy: 0.5385    >>>myCallback:on_epoch_end 575\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 577/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6905 - accuracy: 0.5400>>>myCallback:on_epoch_end 576\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5357\n",
      "Epoch 578/700\n",
      "47/56 [========================>.....] - ETA: 0s - loss: 0.6931 - accuracy: 0.5319>>>myCallback:on_epoch_end 577\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 579/700\n",
      "46/56 [=======================>......] - ETA: 0s - loss: 0.6906 - accuracy: 0.5435    >>>myCallback:on_epoch_end 578\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 580/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6923 - accuracy: 0.5385    >>>myCallback:on_epoch_end 579\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 581/700\n",
      "49/56 [=========================>....] - ETA: 0s - loss: 0.6900 - accuracy: 0.5510>>>myCallback:on_epoch_end 580\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 582/700\n",
      "48/56 [========================>.....] - ETA: 0s - loss: 0.6874 - accuracy: 0.5625>>>myCallback:on_epoch_end 581\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 583/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6955 - accuracy: 0.5200    >>>myCallback:on_epoch_end 582\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 584/700\n",
      "50/56 [=========================>....] - ETA: 0s - loss: 0.6893 - accuracy: 0.5600    >>>myCallback:on_epoch_end 583\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 585/700\n",
      "42/56 [=====================>........] - ETA: 0s - loss: 0.6938 - accuracy: 0.5238    >>>myCallback:on_epoch_end 584\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 586/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5273>>>myCallback:on_epoch_end 585\n",
      "56/56 [==============================] - 0s 932us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 587/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6945 - accuracy: 0.5192>>>myCallback:on_epoch_end 586\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 588/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6917 - accuracy: 0.5385>>>myCallback:on_epoch_end 587\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 589/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6929 - accuracy: 0.5283    >>>myCallback:on_epoch_end 588\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 590/700\n",
      "39/56 [===================>..........] - ETA: 0s - loss: 0.6875 - accuracy: 0.5641>>>myCallback:on_epoch_end 589\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 591/700\n",
      "46/56 [=======================>......] - ETA: 0s - loss: 0.6867 - accuracy: 0.5652>>>myCallback:on_epoch_end 590\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 592/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6928 - accuracy: 0.5385>>>myCallback:on_epoch_end 591\n",
      "56/56 [==============================] - 0s 1000us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 593/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6921 - accuracy: 0.5283>>>myCallback:on_epoch_end 592\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6911 - accuracy: 0.5357\n",
      "Epoch 594/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6908 - accuracy: 0.5472>>>myCallback:on_epoch_end 593\n",
      "56/56 [==============================] - 0s 964us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 595/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6906 - accuracy: 0.5472    >>>myCallback:on_epoch_end 594\n",
      "56/56 [==============================] - 0s 991us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 596/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6911 - accuracy: 0.5472    >>>myCallback:on_epoch_end 595\n",
      "56/56 [==============================] - 0s 990us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 597/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6977 - accuracy: 0.5094    >>>myCallback:on_epoch_end 596\n",
      "56/56 [==============================] - 0s 974us/step - loss: 0.6949 - accuracy: 0.5357\n",
      "Epoch 598/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6869 - accuracy: 0.5686>>>myCallback:on_epoch_end 597\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 599/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5273    >>>myCallback:on_epoch_end 598\n",
      "56/56 [==============================] - 0s 945us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 600/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6928 - accuracy: 0.5370>>>myCallback:on_epoch_end 599\n",
      "56/56 [==============================] - 0s 966us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 601/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6917 - accuracy: 0.5385    >>>myCallback:on_epoch_end 600\n",
      "56/56 [==============================] - 0s 999us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 602/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6912 - accuracy: 0.5472    >>>myCallback:on_epoch_end 601\n",
      "56/56 [==============================] - 0s 992us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 603/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6929 - accuracy: 0.5577>>>myCallback:on_epoch_end 602\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6957 - accuracy: 0.5357\n",
      "Epoch 604/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6912 - accuracy: 0.5385>>>myCallback:on_epoch_end 603\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 605/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6949 - accuracy: 0.5385    >>>myCallback:on_epoch_end 604\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5357\n",
      "Epoch 606/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6879 - accuracy: 0.5660>>>myCallback:on_epoch_end 605\n",
      "56/56 [==============================] - 0s 993us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 607/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6907 - accuracy: 0.5490    >>>myCallback:on_epoch_end 606\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 608/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6900 - accuracy: 0.5472    >>>myCallback:on_epoch_end 607\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 609/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6944 - accuracy: 0.5185>>>myCallback:on_epoch_end 608\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 610/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6873 - accuracy: 0.5660    >>>myCallback:on_epoch_end 609\n",
      "56/56 [==============================] - 0s 978us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 611/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6940 - accuracy: 0.5185    >>>myCallback:on_epoch_end 610\n",
      "56/56 [==============================] - 0s 956us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 612/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6899 - accuracy: 0.5577    >>>myCallback:on_epoch_end 611\n",
      "56/56 [==============================] - 0s 988us/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 613/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6936 - accuracy: 0.5283    >>>myCallback:on_epoch_end 612\n",
      "56/56 [==============================] - 0s 983us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 614/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6900 - accuracy: 0.5472>>>myCallback:on_epoch_end 613\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 615/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6886 - accuracy: 0.5577    >>>myCallback:on_epoch_end 614\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 616/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6933 - accuracy: 0.5273>>>myCallback:on_epoch_end 615\n",
      "56/56 [==============================] - 0s 950us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 617/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6884 - accuracy: 0.5556    >>>myCallback:on_epoch_end 616\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 618/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6866 - accuracy: 0.5660>>>myCallback:on_epoch_end 617\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6910 - accuracy: 0.5357\n",
      "Epoch 619/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6868 - accuracy: 0.5769>>>myCallback:on_epoch_end 618\n",
      "56/56 [==============================] - 0s 997us/step - loss: 0.6937 - accuracy: 0.5357\n",
      "Epoch 620/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6855 - accuracy: 0.5769>>>myCallback:on_epoch_end 619\n",
      "56/56 [==============================] - 0s 990us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 621/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6910 - accuracy: 0.5385>>>myCallback:on_epoch_end 620\n",
      "56/56 [==============================] - 0s 984us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 622/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6304 - accuracy: 1.0000>>>myCallback:on_epoch_end 621\n",
      "56/56 [==============================] - 0s 918us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 623/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6935 - accuracy: 0.5283>>>myCallback:on_epoch_end 622\n",
      "56/56 [==============================] - 0s 981us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 624/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6896 - accuracy: 0.5556>>>myCallback:on_epoch_end 623\n",
      "56/56 [==============================] - 0s 960us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 625/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5283>>>myCallback:on_epoch_end 624\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 626/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6937 - accuracy: 0.5385>>>myCallback:on_epoch_end 625\n",
      "56/56 [==============================] - 0s 996us/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 627/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6936 - accuracy: 0.5185>>>myCallback:on_epoch_end 626\n",
      "56/56 [==============================] - 0s 990us/step - loss: 0.6916 - accuracy: 0.5357\n",
      "Epoch 628/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6928 - accuracy: 0.5385    >>>myCallback:on_epoch_end 627\n",
      "56/56 [==============================] - 0s 998us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 629/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6951 - accuracy: 0.5294>>>myCallback:on_epoch_end 628\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 630/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6892 - accuracy: 0.5686    >>>myCallback:on_epoch_end 629\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.5357\n",
      "Epoch 631/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6952 - accuracy: 0.5185>>>myCallback:on_epoch_end 630\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6934 - accuracy: 0.5357\n",
      "Epoch 632/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6878 - accuracy: 0.5660>>>myCallback:on_epoch_end 631\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 633/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6947 - accuracy: 0.5294>>>myCallback:on_epoch_end 632\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 634/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6935 - accuracy: 0.5283    >>>myCallback:on_epoch_end 633\n",
      "56/56 [==============================] - 0s 996us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 635/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6895 - accuracy: 0.5577>>>myCallback:on_epoch_end 634\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 636/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6872 - accuracy: 0.5686    >>>myCallback:on_epoch_end 635\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 637/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6873 - accuracy: 0.5769>>>myCallback:on_epoch_end 636\n",
      "56/56 [==============================] - 0s 994us/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 638/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6911 - accuracy: 0.5472>>>myCallback:on_epoch_end 637\n",
      "56/56 [==============================] - 0s 989us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 639/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6902 - accuracy: 0.5472    >>>myCallback:on_epoch_end 638\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 640/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6943 - accuracy: 0.5185>>>myCallback:on_epoch_end 639\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 641/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6921 - accuracy: 0.5455    >>>myCallback:on_epoch_end 640\n",
      "56/56 [==============================] - 0s 941us/step - loss: 0.6936 - accuracy: 0.5357\n",
      "Epoch 642/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6178 - accuracy: 1.0000>>>myCallback:on_epoch_end 641\n",
      "56/56 [==============================] - 0s 890us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 643/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.5357>>>myCallback:on_epoch_end 642\n",
      "56/56 [==============================] - 0s 935us/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 644/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6937 - accuracy: 0.5185    >>>myCallback:on_epoch_end 643\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 645/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6958 - accuracy: 0.5185    >>>myCallback:on_epoch_end 644\n",
      "56/56 [==============================] - 0s 992us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 646/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6957 - accuracy: 0.5185>>>myCallback:on_epoch_end 645\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6938 - accuracy: 0.5357\n",
      "Epoch 647/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.5455>>>myCallback:on_epoch_end 646\n",
      "56/56 [==============================] - 0s 961us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 648/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6932 - accuracy: 0.5273    >>>myCallback:on_epoch_end 647\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 649/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5357    >>>myCallback:on_epoch_end 648\n",
      "56/56 [==============================] - 0s 927us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 650/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6927 - accuracy: 0.5273    >>>myCallback:on_epoch_end 649\n",
      "56/56 [==============================] - 0s 928us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 651/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6915 - accuracy: 0.5370>>>myCallback:on_epoch_end 650\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 652/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6922 - accuracy: 0.5370    >>>myCallback:on_epoch_end 651\n",
      "56/56 [==============================] - 0s 952us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 653/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5370    >>>myCallback:on_epoch_end 652\n",
      "56/56 [==============================] - 0s 969us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 654/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6995 - accuracy: 0.5273    >>>myCallback:on_epoch_end 653\n",
      "56/56 [==============================] - 0s 945us/step - loss: 0.6982 - accuracy: 0.5357\n",
      "Epoch 655/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6930 - accuracy: 0.5370    >>>myCallback:on_epoch_end 654\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 656/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5357    >>>myCallback:on_epoch_end 655\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 657/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5357>>>myCallback:on_epoch_end 656\n",
      "56/56 [==============================] - 0s 929us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 658/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5357>>>myCallback:on_epoch_end 657\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 659/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5273>>>myCallback:on_epoch_end 658\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 660/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6941 - accuracy: 0.5192    >>>myCallback:on_epoch_end 659\n",
      "56/56 [==============================] - 0s 994us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 661/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6914 - accuracy: 0.5455    >>>myCallback:on_epoch_end 660\n",
      "56/56 [==============================] - 0s 944us/step - loss: 0.6929 - accuracy: 0.5357\n",
      "Epoch 662/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6915 - accuracy: 0.5370>>>myCallback:on_epoch_end 661\n",
      "56/56 [==============================] - 0s 990us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 663/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.5357    >>>myCallback:on_epoch_end 662\n",
      "56/56 [==============================] - 0s 910us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 664/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6922 - accuracy: 0.5357    >>>myCallback:on_epoch_end 663\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6922 - accuracy: 0.5357\n",
      "Epoch 665/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.5357>>>myCallback:on_epoch_end 664\n",
      "56/56 [==============================] - 0s 923us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 666/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6849 - accuracy: 0.5769>>>myCallback:on_epoch_end 665\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 667/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5357>>>myCallback:on_epoch_end 666\n",
      "56/56 [==============================] - 0s 916us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 668/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.5357>>>myCallback:on_epoch_end 667\n",
      "56/56 [==============================] - 0s 911us/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 669/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6870 - accuracy: 0.5686>>>myCallback:on_epoch_end 668\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 670/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6934 - accuracy: 0.5273>>>myCallback:on_epoch_end 669\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6923 - accuracy: 0.5357\n",
      "Epoch 671/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5357    >>>myCallback:on_epoch_end 670\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 672/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6915 - accuracy: 0.5455>>>myCallback:on_epoch_end 671\n",
      "56/56 [==============================] - 0s 935us/step - loss: 0.6931 - accuracy: 0.5357\n",
      "Epoch 673/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5283>>>myCallback:on_epoch_end 672\n",
      "56/56 [==============================] - 0s 982us/step - loss: 0.6921 - accuracy: 0.5357\n",
      "Epoch 674/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6931 - accuracy: 0.5370>>>myCallback:on_epoch_end 673\n",
      "56/56 [==============================] - 0s 972us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 675/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6924 - accuracy: 0.5273>>>myCallback:on_epoch_end 674\n",
      "56/56 [==============================] - 0s 957us/step - loss: 0.6912 - accuracy: 0.5357\n",
      "Epoch 676/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6949 - accuracy: 0.5185>>>myCallback:on_epoch_end 675\n",
      "56/56 [==============================] - 0s 973us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 677/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6945 - accuracy: 0.5273    >>>myCallback:on_epoch_end 676\n",
      "56/56 [==============================] - 0s 951us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 678/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6913 - accuracy: 0.5455>>>myCallback:on_epoch_end 677\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 679/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6903 - accuracy: 0.5556    >>>myCallback:on_epoch_end 678\n",
      "56/56 [==============================] - 0s 979us/step - loss: 0.6930 - accuracy: 0.5357\n",
      "Epoch 680/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5357    >>>myCallback:on_epoch_end 679\n",
      "56/56 [==============================] - 0s 925us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 681/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.5357>>>myCallback:on_epoch_end 680\n",
      "56/56 [==============================] - 0s 912us/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 682/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6920 - accuracy: 0.5273>>>myCallback:on_epoch_end 681\n",
      "56/56 [==============================] - 0s 971us/step - loss: 0.6910 - accuracy: 0.5357\n",
      "Epoch 683/700\n",
      "51/56 [==========================>...] - ETA: 0s - loss: 0.6904 - accuracy: 0.5490    >>>myCallback:on_epoch_end 682\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 684/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6938 - accuracy: 0.5185>>>myCallback:on_epoch_end 683\n",
      "56/56 [==============================] - 0s 949us/step - loss: 0.6915 - accuracy: 0.5357\n",
      "Epoch 685/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.7625 - accuracy: 0.0000e+00>>>myCallback:on_epoch_end 684\n",
      "56/56 [==============================] - 0s 895us/step - loss: 0.6917 - accuracy: 0.5357\n",
      "Epoch 686/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6939 - accuracy: 0.5192>>>myCallback:on_epoch_end 685\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6919 - accuracy: 0.5357\n",
      "Epoch 687/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6889 - accuracy: 0.5556>>>myCallback:on_epoch_end 686\n",
      "56/56 [==============================] - 0s 970us/step - loss: 0.6924 - accuracy: 0.5357\n",
      "Epoch 688/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6939 - accuracy: 0.5273>>>myCallback:on_epoch_end 687\n",
      "56/56 [==============================] - 0s 939us/step - loss: 0.6927 - accuracy: 0.5357\n",
      "Epoch 689/700\n",
      "56/56 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5357>>>myCallback:on_epoch_end 688\n",
      "56/56 [==============================] - 0s 923us/step - loss: 0.6935 - accuracy: 0.5357\n",
      "Epoch 690/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6941 - accuracy: 0.5273>>>myCallback:on_epoch_end 689\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 691/700\n",
      "54/56 [===========================>..] - ETA: 0s - loss: 0.6946 - accuracy: 0.5370>>>myCallback:on_epoch_end 690\n",
      "56/56 [==============================] - 0s 947us/step - loss: 0.6946 - accuracy: 0.5357\n",
      "Epoch 692/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6930 - accuracy: 0.5273>>>myCallback:on_epoch_end 691\n",
      "56/56 [==============================] - 0s 963us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 693/700\n",
      "53/56 [===========================>..] - ETA: 0s - loss: 0.6945 - accuracy: 0.5094    >>>myCallback:on_epoch_end 692\n",
      "56/56 [==============================] - 0s 980us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 694/700\n",
      " 1/56 [..............................] - ETA: 0s - loss: 0.6334 - accuracy: 1.0000>>>myCallback:on_epoch_end 693\n",
      "56/56 [==============================] - 0s 900us/step - loss: 0.6920 - accuracy: 0.5357\n",
      "Epoch 695/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5273    >>>myCallback:on_epoch_end 694\n",
      "56/56 [==============================] - 0s 965us/step - loss: 0.6914 - accuracy: 0.5357\n",
      "Epoch 696/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6929 - accuracy: 0.5273    >>>myCallback:on_epoch_end 695\n",
      "56/56 [==============================] - 0s 953us/step - loss: 0.6918 - accuracy: 0.5357\n",
      "Epoch 697/700\n",
      "52/56 [==========================>...] - ETA: 0s - loss: 0.6925 - accuracy: 0.5385    >>>myCallback:on_epoch_end 696\n",
      "56/56 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5357\n",
      "Epoch 698/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6916 - accuracy: 0.5455>>>myCallback:on_epoch_end 697\n",
      "56/56 [==============================] - 0s 962us/step - loss: 0.6932 - accuracy: 0.5357\n",
      "Epoch 699/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6958 - accuracy: 0.5273>>>myCallback:on_epoch_end 698\n",
      "56/56 [==============================] - 0s 960us/step - loss: 0.6950 - accuracy: 0.5357\n",
      "Epoch 700/700\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.6923 - accuracy: 0.5455>>>myCallback:on_epoch_end 699\n",
      "56/56 [==============================] - 0s 934us/step - loss: 0.6936 - accuracy: 0.5357\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "history = model.fit(x_train,y_train,epochs=700,batch_size=1,verbose=1,callbacks=[callbacks]) # verbose=1, 메세지를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5def3ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "epoch_count = range(1, len(history.history['loss']) + 1)\n",
    "plt.plot(epoch_count, history.history['loss'], 'r-')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecda3c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 996us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "preds = model.predict(x_train)\n",
    "np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b88346b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6732 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6731500625610352, 0.6666666865348816]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가\n",
    "x_data = xy[56:, :-1 ]\n",
    "y_data = xy[56:, [-1] ]\n",
    "\n",
    "x_test = np.array(x_data,dtype=np.float32)\n",
    "y_test = np.array(y_data,dtype=np.float32)\n",
    "\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8747ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
